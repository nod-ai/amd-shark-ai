# Copyright 2026 Advanced Micro Devices, Inc.
#
# Licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

import argparse
import logging
import os
import shlex
import shutil
import subprocess
import sys
import tempfile
import traceback
from datetime import datetime
from pathlib import Path
from typing import Iterator, Optional
from typing_extensions import override

from amdsharktuner import common, libtuner


class FusilliPathConfig(libtuner.PathConfig):
    """Path configuration for Fusilli tuner with Fusilli-specific directory naming."""

    def _name_base_dir(self) -> Path:
        timestamp = datetime.now().strftime("%Y_%m_%d_%H_%M")
        return Path(f"./fusilli_tuning_{timestamp}")

    def create_benchmark_path_config(self, benchmark_name: str) -> libtuner.PathConfig:
        """Create a PathConfig for a specific benchmark under the main tuning directory."""
        base_dir = self.base_dir

        class BenchmarkPathConfig(libtuner.PathConfig):
            def _name_base_dir(self) -> Path:
                return base_dir / benchmark_name

        return BenchmarkPathConfig()


class FusilliTuner(libtuner.TuningClient):
    """Tuning client for IREE kernels generated by Fusilli."""

    def __init__(self, tuner_context: common.TunerContext):
        super().__init__(tuner_context)
        self.compile_flags: list[str] = []
        self.benchmark_flags: list[str] = []
        self.compile_timeout: Optional[float] = 16
        self.benchmark_timeout: Optional[float] = None
        self.auto_benchmark_timeout: bool = True

    @override
    def get_iree_compile_flags(self) -> list[str]:
        return self.compile_flags

    @override
    def get_iree_compile_timeout_s(self) -> Optional[float]:
        return self.compile_timeout

    @override
    def get_iree_benchmark_module_flags(self) -> list[str]:
        return self.benchmark_flags

    @override
    def get_iree_benchmark_timeout_s(self) -> Optional[float]:
        return self.benchmark_timeout

    @override
    def is_auto_iree_benchmark_timeout(self) -> bool:
        return self.auto_benchmark_timeout

    @override
    def should_prune_slower_candidates(self) -> bool:
        # FusilliTuner has only one phase, so prune candidates if all are slower
        # than baseline.
        return True


def insert_placeholder_input_file(argv: list[str]) -> list[str]:
    """Inserts 'fusilli.mlir' placeholder into argv to satisfy libtuner's required
    input_file argument (Fusilli generates files internally, not from command line)."""
    return [argv[0], "fusilli.mlir"] + argv[1:]


def parse_args(argv: list[str]) -> tuple[argparse.Namespace, list[str]]:
    """Parse command line arguments.

    Args:
        argv: Command line arguments to parse (typically sys.argv).

    Returns:
        A tuple of (parsed_args, fusilli_op_args) where fusilli_op_args contains
        the Fusilli operation arguments (conv, matmul parameters).
    """

    parser = argparse.ArgumentParser(
        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter
    )
    fusilli_args = parser.add_argument_group("Fusilli Tuner Options")
    fusilli_args.add_argument(
        "--fusilli-args",
        type=str,
        help='Fusilli operation command. Examples: --fusilli-args="conv -F 1 ..." or --fusilli-args "conv -F 1 ..."',
    )
    fusilli_args.add_argument(
        "--commands-file",
        type=str,
        help="Read Fusilli commands from a file (one per line).",
    )
    fusilli_args.add_argument(
        "--output-td-spec",
        type=Path,
        default="tuning-spec.mlir",
        help="Path to write the best tuned spec.",
    )
    fusilli_args.add_argument(
        "--tmp-dir",
        type=str,
        default="",
        help="Directory to save temporary files. If not specified, a temporary directory will be created.",
    )
    fusilli_args.add_argument(
        "--fusilli-driver",
        type=str,
        default="fusilli_benchmark_driver",
        help="Path to the fusilli_benchmark_driver binary.",
    )
    fusilli_args.add_argument(
        "--fusilli-num-dispatch-candidates",
        type=int,
        default=None,
        help="Number of top dispatch candidates to return (default: return all benchmarked candidates).",
    )
    fusilli_args.add_argument(
        "--fusilli-dispatch-benchmark-timeout-mins",
        type=float,
        default=None,
        help="Time budget in minutes per dispatch for benchmarking all candidates.",
    )

    # Placeholder to satisfy libtuner's required input_file argument.
    # Fusilli generates benchmark files at runtime, not from a pre-existing file.
    # TODO(Bangtian): Remove dispatch tuner's input file requirement, then use dispatch tuner.
    argv_with_placeholder = insert_placeholder_input_file(argv)

    # Temporarily override sys.argv for libtuner.parse_arguments.
    original_argv = sys.argv
    sys.argv = argv_with_placeholder
    try:
        args = libtuner.parse_arguments(parser)
    finally:
        sys.argv = original_argv

    if "--codegen-pipeline" not in argv_with_placeholder:
        # Default to tile_and_fuse for Fusilli operations.
        args.codegen_pipeline = libtuner.CodegenPipelines.llvmgpu_tile_and_fuse

    # Extract Fusilli operation arguments from --fusilli-args.
    fusilli_op_args = shlex.split(args.fusilli_args) if args.fusilli_args else []

    return args, fusilli_op_args


def load_commands_from_file_or_args(
    commands_file: Optional[str], fusilli_op_args: list[str]
) -> list[list[str]]:
    # Split tab-separated arguments (for easier copy-pasting from TSV files).
    fusilli_op_args = [a for arg in fusilli_op_args for a in arg.split("\t")]

    # Load Fusilli commands from file if specified, otherwise use command-line arguments.
    if not commands_file:
        return [fusilli_op_args]

    # Validate that fusilli_op_args is empty when using a commands file.
    if fusilli_op_args:
        raise ValueError("Cannot specify both --commands-file and --fusilli-args.")

    with open(commands_file) as f:
        return [
            shlex.split(line)
            for line in f.readlines()
            if line.strip() and not line.startswith("#")
        ]


def build_compile_args(compile_command: str, benchmarks_dir: Path) -> list[str]:
    fusilli_compile_flags: list[str] = shlex.split(compile_command)

    # Start with iree-compile and filter out unwanted flags from fusilli flags.
    # See fusilli/include/fusilli/backend/compile_command.h for flag formats.
    compile_args: list[str] = ["iree-compile"]
    args_iter: Iterator[str] = iter(fusilli_compile_flags[1:])
    for arg in args_iter:
        # Skip output flag (Fusilli generates "-o" as separate argument + path).
        if arg == "-o":
            next(args_iter, None)
            continue
        # Skip scheduling statistics flags (Fusilli generates with "=" syntax).
        if arg.startswith("--iree-scheduling-dump-statistics-format") or arg.startswith(
            "--iree-scheduling-dump-statistics-file"
        ):
            continue
        compile_args.append(arg)

    # Add tuner-specific flags.
    compile_args += [
        "--iree-config-add-tuner-attributes",
        "--iree-hal-dump-executable-benchmarks-to",
        str(benchmarks_dir),
        "-o",
        os.devnull,
    ]

    return compile_args


def run_fusilli_benchmark_driver(
    fusilli_driver: str,
    cli_args: list[str],
    cache_dir: Path,
) -> None:
    # Use --dump to generate MLIR and compile command artifacts, --iter 1 since
    # we only need file generation (not actual benchmarking).
    cmd: list[str] = [fusilli_driver, "--dump", "--iter", "1"] + cli_args

    # Override FUSILLI_CACHE_DIR to control where Fusilli dumps the generated
    # MLIR and compilation flags.
    env: dict[str, str] = os.environ.copy()
    env["FUSILLI_CACHE_DIR"] = str(cache_dir)

    logging.info(f"> {shlex.join(cmd)}")
    logging.info(f"  FUSILLI_CACHE_DIR={cache_dir}")

    result: subprocess.CompletedProcess[str] = subprocess.run(
        cmd, env=env, capture_output=True, text=True
    )

    # Exit early on success.
    if result.returncode == 0:
        if result.stdout:
            logging.debug(f"Fusilli benchmark driver stdout:\n{result.stdout}")
        return

    # Handle failure.
    logging.error(
        f"Fusilli benchmark driver failed with return code {result.returncode}"
    )
    if result.stdout:
        logging.error(f"stdout: {result.stdout}")
    if result.stderr:
        logging.error(f"stderr: {result.stderr}")
    raise RuntimeError(f"Fusilli benchmark driver failed with code {result.returncode}")


def find_cached_artifacts(base_dir: Path) -> tuple[Path, Path]:
    """Find source MLIR and compile command from Fusilli cache.

    Fusilli cache structure controlled by FUSILLI_CACHE_DIR environment variable:
        base_dir/                     # User-specified or temp directory (FUSILLI_CACHE_DIR)
          .cache/fusilli/             # Fusilli's internal cache structure
            <graph_hash>/             # Graph-specific directory (one per operation)
              iree-compile-input.mlir # Generated MLIR for the operation
              iree-compile-command.txt # Compile command used by Fusilli

    Args:
        base_dir: The base directory where FUSILLI_CACHE_DIR environment variable was set to.
                  Fusilli creates its cache at base_dir/.cache/fusilli/

    Returns:
        Tuple of (source_mlir_path, compile_command_path).
    """
    fusilli_cache: Path = base_dir / ".cache" / "fusilli"

    if not fusilli_cache.exists():
        raise FileNotFoundError(f"Fusilli cache not found at {fusilli_cache}")

    # Find the graph directory (there should be exactly one after running
    # with --dump).
    graph_dirs: list[Path] = list(fusilli_cache.iterdir())
    if not graph_dirs:
        raise FileNotFoundError(f"No graph directories found in {fusilli_cache}")

    graph_dir: Path = graph_dirs[0]

    source_mlir_path: Path = graph_dir / "iree-compile-input.mlir"
    compile_command_path: Path = graph_dir / "iree-compile-command.txt"

    if not source_mlir_path.exists():
        raise FileNotFoundError(f"Source MLIR not found at {source_mlir_path}")
    if not compile_command_path.exists():
        raise FileNotFoundError(f"Compile command not found at {compile_command_path}")

    # Validate paths to prevent path traversal attacks.
    try:
        source_mlir_path.resolve().relative_to(base_dir.resolve())
        compile_command_path.resolve().relative_to(base_dir.resolve())
    except ValueError as e:
        raise ValueError(f"Path traversal detected: {e}")

    return source_mlir_path, compile_command_path


def tune_fusilli_dispatch(
    benchmark_path: Path,
    args: argparse.Namespace,
    path_config: libtuner.PathConfig,
    root_logger: logging.Logger,
    summary_handler: logging.Handler,
    starter_td_spec: Optional[Path],
) -> Optional[Path]:
    """Tune a single Fusilli dispatch."""
    args.input_file = benchmark_path

    if starter_td_spec and starter_td_spec.exists():
        args.starter_td_spec = starter_td_spec
    else:
        args.starter_td_spec = None

    logging.info("Generating candidate tuning specs...")
    with common.TunerContext(logger=root_logger) as tuner_context:
        tuner_context.logger.addHandler(summary_handler)
        fusilli_tuner = FusilliTuner(tuner_context)
        candidates = libtuner.generate_candidate_specs(args, path_config, fusilli_tuner)
        logging.info(f"Stored candidate tuning specs in {path_config.specs_dir}")

        logging.info("Compiling dispatch candidates...")
        fusilli_tuner.compile_flags = ["--compile-from=executable-sources"]
        compiled_candidates = libtuner.compile(
            args, path_config, candidates, fusilli_tuner
        )

        logging.info("Benchmarking compiled dispatch candidates...")
        fusilli_tuner.benchmark_flags = [
            "--input=1",
            "--benchmark_repetitions=3",
        ]
        top_candidates = libtuner.benchmark(
            args,
            path_config,
            compiled_candidates,
            fusilli_tuner,
            args.fusilli_num_dispatch_candidates,
            args.fusilli_dispatch_benchmark_timeout_mins,
        )

        if not top_candidates:
            logging.critical("No tuning candidates performed better than the baseline.")
            return None

        logging.info(f"Top dispatch candidates: {top_candidates}")
        for candidate_id in top_candidates:
            logging.info(
                f"{fusilli_tuner.candidate_trackers[candidate_id].spec_path.resolve()}"
            )

        # Save the best (first) tuning spec to the output file.
        best_candidate_id = top_candidates[0]
        best_spec_path = fusilli_tuner.candidate_trackers[best_candidate_id].spec_path
        shutil.copy(best_spec_path, args.output_td_spec)
        logging.info(f"Saved best tuning spec to: {args.output_td_spec}")
        print(f"Saved best tuning spec to: {args.output_td_spec}")

    return args.output_td_spec


def process_fusilli_command(
    cli_args: list[str],
    args: argparse.Namespace,
    fusilli_path_config: FusilliPathConfig,
    root_logger: logging.Logger,
    starter_td_spec: Optional[Path],
    command_idx: int,
) -> Optional[Path]:
    """Process a single Fusilli command through compilation and tuning."""
    # Set up temporary directory.
    if args.tmp_dir:
        tmp_dir = Path(args.tmp_dir)
        tmp_dir.mkdir(parents=True, exist_ok=True)
        logging.info(f"Using user-specified temporary directory: {tmp_dir}")
    else:
        # Ensure parent directory exists before creating temp directory.
        Path("fusilli_tuner").mkdir(exist_ok=True)
        tmp_dir = Path(tempfile.mkdtemp(dir="fusilli_tuner", prefix="fusilli_cache_"))
        logging.info(f"Created temporary directory: {tmp_dir}")

    # Run Fusilli benchmark driver with --dump to generate source MLIR.
    run_fusilli_benchmark_driver(args.fusilli_driver, cli_args, tmp_dir)

    # Find the cached artifacts.
    source_mlir_path, compile_command_path = find_cached_artifacts(tmp_dir)
    logging.debug(f"source_mlir_path: {source_mlir_path}")

    # Read the compile command.
    with open(compile_command_path) as f:
        compile_command = f.read().strip()

    # Build compile arguments with tuner-specific flags.
    benchmarks_dir = tmp_dir / "benchmarks"
    compile_args = build_compile_args(compile_command, benchmarks_dir)

    logging.info(f"> {shlex.join(compile_args)}")
    compile_result = subprocess.run(compile_args, capture_output=True, text=True)

    if compile_result.returncode != 0:
        logging.error(
            f"iree-compile failed with return code {compile_result.returncode}"
        )
        if compile_result.stdout:
            logging.error(f"stdout: {compile_result.stdout}")
        if compile_result.stderr:
            logging.error(f"stderr: {compile_result.stderr}")
        raise RuntimeError(f"iree-compile failed with code {compile_result.returncode}")

    best_spec_path = None

    # Process all generated benchmark files.
    if not benchmarks_dir.exists():
        logging.warning(f"No benchmarks directory found at {benchmarks_dir}")
        return None

    benchmark_files = list(os.listdir(benchmarks_dir))
    for benchmark_file in benchmark_files:
        benchmark_path = benchmarks_dir / benchmark_file
        logging.info(f"Tuning benchmark: {benchmark_path}")

        # Extract benchmark name from filename (remove _benchmark.mlir suffix).
        benchmark_name = benchmark_file.replace("_benchmark.mlir", "")

        # Create a dedicated PathConfig for this benchmark.
        # Use operation type + counter as suffix to avoid collisions and provide context.
        op_type = cli_args[0] if cli_args else "unknown"
        unique_benchmark_name = f"{benchmark_name}_{op_type}_{command_idx}"
        benchmark_path_config = fusilli_path_config.create_benchmark_path_config(
            unique_benchmark_name
        )
        benchmark_path_config.base_dir.mkdir(parents=True, exist_ok=True)

        # Create benchmark-specific summary log.
        summary_log_file = benchmark_path_config.base_dir / "summary.log"
        summary_handler = logging.FileHandler(summary_log_file)
        summary_handler.setLevel(logging.INFO)
        summary_handler.setFormatter(
            logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
        )

        try:
            result = tune_fusilli_dispatch(
                benchmark_path,
                args,
                benchmark_path_config,
                root_logger,
                summary_handler,
                starter_td_spec,
            )
            if result:
                best_spec_path = result

            if benchmark_path_config.run_log is not None:
                print("\nCheck the detailed execution logs in:")
                print(benchmark_path_config.run_log.resolve())
            print("Check the summary in:")
            print(summary_log_file.resolve())

        except Exception as err:
            traceback.print_exception(err)

        finally:
            # Remove handler from logger to prevent log accumulation.
            root_logger.removeHandler(summary_handler)
            summary_handler.close()

    return args.output_td_spec if best_spec_path else None


def main() -> None:
    """Main entry point for the Fusilli tuner."""
    args, fusilli_op_args = parse_args(sys.argv)

    if args.commands_file and fusilli_op_args:
        raise ValueError("Cannot specify both --commands-file and --fusilli-args")

    # Create main tuning directory.
    fusilli_path_config = FusilliPathConfig()
    fusilli_path_config.base_dir.mkdir(parents=True, exist_ok=True)

    root_logger = libtuner.setup_logging(args, fusilli_path_config)
    print(fusilli_path_config.run_log)

    logging.warning("Fusilli Tuner is still experimental")

    if not args.dry_run:
        logging.info("Validating devices")
        libtuner.validate_devices(args.devices)
        logging.info("Validation successful!")

    fusilli_commands = load_commands_from_file_or_args(
        args.commands_file, fusilli_op_args
    )

    starter_td_spec: Optional[Path] = args.starter_td_spec
    for idx, cli_args in enumerate(fusilli_commands):
        message = f">>> ({idx+1}/{len(fusilli_commands)}) {shlex.join(cli_args)}"
        logging.info(message)

        result_spec = process_fusilli_command(
            cli_args,
            args,
            fusilli_path_config,
            root_logger,
            starter_td_spec,
            idx + 1,
        )

        # Update starter spec for next iteration if tuning succeeded.
        if result_spec:
            starter_td_spec = result_spec


if __name__ == "__main__":
    main()
